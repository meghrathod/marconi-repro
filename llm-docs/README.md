# LLM Serving Documentation

Documentation for LLM serving with [SGLang](https://github.com/sgl-project/sglang), Mamba/hybrid model support, and [Marconi](https://arxiv.org/abs/2411.19379) integration.

---

## Documents

| Doc | Description |
|-----|-------------|
| [01-sglang-overview.md](01-sglang-overview.md) | SGLang basics and advanced: RadixAttention, prefix caching, HiCache, hybrid models |
| [02-mamba-sglang-implementation.md](02-mamba-sglang-implementation.md) | How Mamba radix cache is implemented in SGLang ([PR #11214](https://github.com/sgl-project/sglang/pull/11214)) |
| [03-marconi-integration.md](03-marconi-integration.md) | Marconi strategy, integration plan, test plan, replication strategy, quick start |

---

## External References

| Topic | Link |
|-------|------|
| SGLang docs | [docs.sglang.io](https://docs.sglang.io/) |
| SGLang GitHub | [sgl-project/sglang](https://github.com/sgl-project/sglang) |
| Marconi paper | [arXiv:2411.19379](https://arxiv.org/abs/2411.19379) |
| Marconi repo | [ruipeterpan/marconi](https://github.com/ruipeterpan/marconi) |
